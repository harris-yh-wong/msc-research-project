{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM\n",
    "- run more baseline models with sklearn pipeline\n",
    "- input data: data with preprocessed routine as of Mar22\n",
    "\n",
    "Created: 23 Mar 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODULES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates\n",
    "import matplotlib.patches\n",
    "import datetime as dt\n",
    "import ast\n",
    "\n",
    "## custom modules\n",
    "# import sys  \n",
    "# sys.path.append('../../scripts')\n",
    "\n",
    "import import_data\n",
    "import clean_data\n",
    "import mappings\n",
    "import plotting\n",
    "import report\n",
    "import helper\n",
    "\n",
    "##### OPTIONS\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# autoreload external modules after saving changes to disk\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "##### DIRECTORIES\n",
    "proj_dir = Path('.') / '..' / '..'\n",
    "source_data_dir = proj_dir/'data'/'source'\n",
    "clean_data_dir =  proj_dir/'data'/'clean'\n",
    "viz_dir = proj_dir/'viz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import feather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# tune\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# performance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# pipe\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_PREPROCESSED_DATA = proj_dir/'data'/'clean'/'preprocessMar22'/'data_merge2.ftr'\n",
    "PATH_TO_FEATURES_SELECTED = proj_dir/'data'/'clean'/'fsMar23all'/'feat_tsfresh_select.ftr'\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "### INITIAL SPLIT\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "### TUNING\n",
    "N_JOBS = -2 # all but 1 CPUs\n",
    "KFOLD = 5\n",
    "SCORING = 'balanced_accuracy'\n",
    "\n",
    "### CROSS VALIDATION\n",
    "N_SPLITS = 5\n",
    "N_REPEATS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_defaults = {\n",
    "    \"n_jobs\": N_JOBS,\n",
    "    \"cv\": KFOLD,\n",
    "    \"scoring\": SCORING,\n",
    "    \"return_train_score\": True\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = pd.read_feather(PATH_TO_FEATURES_SELECTED)\n",
    "df = pd.read_feather(PATH_TO_PREPROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key does match.\n"
     ]
    }
   ],
   "source": [
    "df['target'] = df['phq'] > 10\n",
    "_, y = clean_data.generate_ts_y(df)\n",
    "y = y[fs['index']]\n",
    "\n",
    "# check index does match\n",
    "if np.array_equal(y.index.values, fs['index'].values):\n",
    "    print(\"Primary key does match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fs.loc[:, fs.columns != 'index'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2002, 422)\n",
      "Training Labels Shape: (2002,)\n",
      "Testing Features Shape: (858, 422)\n",
      "Testing Labels Shape: (858,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=SEED, test_size=TEST_SIZE)\n",
    "\n",
    "report.report_train_test_split(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(pipeline, params, tune_defaults=False):\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, params)\n",
    "    if tune_defaults:\n",
    "        grid_search.set_params(**tune_defaults)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(params)\n",
    "\n",
    "    ### fit\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    grid_search.cv_results_.keys()\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN - standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Tune: KNN]\n",
      "Performing grid search...\n",
      "pipeline: ['scaler', 'knn']\n",
      "parameters:\n",
      "{'knn__n_neighbors': (3, 5, 7, 9, 11, 13, 15)}\n",
      "Elapsed: 9.7 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_knn = dict()\n",
    "params_knn['knn__n_neighbors']=(3, 5, 7, 9, 11, 13, 15)\n",
    "\n",
    "pipeline_knn_std = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('knn', KNeighborsClassifier())   \n",
    "    ]\n",
    ")\n",
    "\n",
    "with helper.Timer(\"Tune: KNN\"):\n",
    "    search_knn_std = tune_hyperparameters(pipeline_knn_std, params_knn, tune_defaults=tune_defaults)\n",
    "search_knn_std.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC - standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Tune: SVC]\n",
      "Performing grid search...\n",
      "pipeline: ['scaler', 'svc']\n",
      "parameters:\n",
      "{'svc__C': (1, 100), 'svc__gamma': (0.1, 0.001), 'svc__kernel': ['rbf']}\n",
      "Elapsed: 28.6 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params_svc = dict()\n",
    "# params_svc['svc__C'] = (0.1, 1, 10, 100, 1000)\n",
    "# params_svc['svc__gamma'] = (1, 0.1, 0.01, 0.001, 0.0001)\n",
    "# params_svc['svc__kernel'] = ['rbf']\n",
    "\n",
    "params_svc = dict()\n",
    "params_svc['svc__C'] = (1, 100)\n",
    "params_svc['svc__gamma'] = (0.1, 0.001)\n",
    "params_svc['svc__kernel'] = ['rbf']\n",
    "\n",
    "\n",
    "pipeline_svc_std = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('svc', svm.SVC())   \n",
    "    ]\n",
    ")\n",
    "with helper.Timer(\"Tune: SVC\"):\n",
    "    search_svc_std = tune_hyperparameters(pipeline_svc_std, params_svc, tune_defaults=tune_defaults)\n",
    "search_svc_std.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF - no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Tune: RF]\n",
      "Performing grid search...\n",
      "pipeline: ['rf']\n",
      "parameters:\n",
      "{'rf__max_depth': [10, 110, None],\n",
      " 'rf__max_features': ['auto', 'sqrt'],\n",
      " 'rf__min_samples_leaf': (1, 4),\n",
      " 'rf__min_samples_split': (2, 5),\n",
      " 'rf__n_estimators': (10, 100)}\n",
      "Elapsed: 84.9 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 10,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__min_samples_leaf': 4,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params_rf = dict()\n",
    "# params_rf['rf__n_estimators'] = (10, 20, 50, 100, 200)\n",
    "# params_rf['rf__min_samples_split'] = (2, 5)\n",
    "# params_rf['rf__max_features'] = [\"auto\", \"sqrt\"]\n",
    "# params_rf['rf__max_depth'] = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
    "# params_rf['rf__min_samples_leaf'] = (1,2,4)\n",
    "\n",
    "params_rf = dict()\n",
    "params_rf['rf__n_estimators'] = (10, 100)\n",
    "params_rf['rf__min_samples_split'] = (2, 5)\n",
    "params_rf['rf__max_features'] = [\"auto\", \"sqrt\"]\n",
    "params_rf['rf__max_depth'] = [int(x) for x in np.linspace(10, 110, num = 2)] + [None]\n",
    "params_rf['rf__min_samples_leaf'] = (1,4)\n",
    "\n",
    "pipeline_rf = Pipeline(\n",
    "    [ \n",
    "        ('rf', RandomForestClassifier(random_state=SEED))   \n",
    "    ]\n",
    ")\n",
    "with helper.Timer(\"Tune: RF\"):\n",
    "    search_rf = tune_hyperparameters(pipeline_rf, params_rf, tune_defaults)\n",
    "search_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression, regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# [Tune: SVC]\n",
      "Performing grid search...\n",
      "pipeline: ['logistic']\n",
      "parameters:\n",
      "{'logistic__C': [1e-05, 100],\n",
      " 'logistic__penalty': ['none', 'elasticnet'],\n",
      " 'logistic__solver': ['newton-cg', 'lbfgs', 'liblinear']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.61590626 0.60088698        nan        nan        nan        nan\n",
      " 0.61590626 0.60088698        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.73720809 0.61885368        nan        nan        nan        nan\n",
      " 0.73720809 0.61885368        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 78.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harris\\anaconda3\\envs\\msc-thesis\\lib\\site-packages\\sklearn\\utils\\optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logistic__C': 1e-05,\n",
       " 'logistic__penalty': 'none',\n",
       " 'logistic__solver': 'newton-cg'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#! add prefix\n",
    "# params_lr = dict()\n",
    "# params_lr['logistic__solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "# params_lr['logistic__penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "# params_lr['logistic__C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "params_lr = dict()\n",
    "params_lr['logistic__solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "params_lr['logistic__penalty'] = ['none', 'elasticnet']\n",
    "params_lr['logistic__C'] = [1e-5, 100]\n",
    "\n",
    "\n",
    "pipeline_lr = Pipeline(\n",
    "    [ \n",
    "        ('logistic', LogisticRegression())   \n",
    "    ]\n",
    ")\n",
    "with helper.Timer(\"Tune: SVC\"):\n",
    "    search_lr = tune_hyperparameters(pipeline_lr, params_lr, tune_defaults)\n",
    "    \n",
    "search_lr.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### knn\n",
      "Best score: 0.6361371153306452\n",
      "Best params: {'knn__n_neighbors': 9}\n",
      "### svc\n",
      "Best score: 0.6386122836211918\n",
      "Best params: {'svc__C': 1, 'svc__gamma': 0.001, 'svc__kernel': 'rbf'}\n",
      "### rf\n",
      "Best score: 0.636001979992514\n",
      "Best params: {'rf__max_depth': 10, 'rf__max_features': 'auto', 'rf__min_samples_leaf': 4, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n",
      "### logistic\n",
      "Best score: 0.6159062635909771\n",
      "Best params: {'logistic__C': 1e-05, 'logistic__penalty': 'none', 'logistic__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "searches = [search_knn_std, search_svc_std, search_rf, search_lr]\n",
    "names = ['knn', 'svc', 'rf', 'logistic']\n",
    "\n",
    "for name, search in zip(names, searches):\n",
    "    print(f\"### {name}\")\n",
    "    print(f\"Best score: {search.best_score_}\")\n",
    "    print(f'Best params: {search.best_params_}')\n",
    "    if len(search.best_params_)>1:\n",
    "        pass\n",
    "        # plotting.plot_search_results(search)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### knn\n",
      "### svc\n",
      "### rf\n",
      "### logistic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>False</td>\n",
       "      <td>0.712707</td>\n",
       "      <td>0.807933</td>\n",
       "      <td>0.757339</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>0.588391</td>\n",
       "      <td>0.642651</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710956</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.710322</td>\n",
       "      <td>0.698162</td>\n",
       "      <td>0.699995</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>0.710956</td>\n",
       "      <td>0.706678</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svc</td>\n",
       "      <td>False</td>\n",
       "      <td>0.658031</td>\n",
       "      <td>0.795407</td>\n",
       "      <td>0.720227</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc</td>\n",
       "      <td>True</td>\n",
       "      <td>0.648746</td>\n",
       "      <td>0.477573</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svc</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svc</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.653388</td>\n",
       "      <td>0.636490</td>\n",
       "      <td>0.635189</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svc</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.653929</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>0.645101</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>False</td>\n",
       "      <td>0.654822</td>\n",
       "      <td>0.807933</td>\n",
       "      <td>0.723364</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>True</td>\n",
       "      <td>0.655431</td>\n",
       "      <td>0.461741</td>\n",
       "      <td>0.541796</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.655127</td>\n",
       "      <td>0.634837</td>\n",
       "      <td>0.632580</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.655091</td>\n",
       "      <td>0.655012</td>\n",
       "      <td>0.643161</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic</td>\n",
       "      <td>False</td>\n",
       "      <td>0.639042</td>\n",
       "      <td>0.724426</td>\n",
       "      <td>0.679061</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.482850</td>\n",
       "      <td>0.527378</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617716</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.609997</td>\n",
       "      <td>0.603638</td>\n",
       "      <td>0.603219</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.613383</td>\n",
       "      <td>0.617716</td>\n",
       "      <td>0.612058</td>\n",
       "      <td>858.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name         index  precision    recall  f1-score  support\n",
       "0       knn         False   0.712707  0.807933  0.757339    479.0\n",
       "1       knn          True   0.707937  0.588391  0.642651    379.0\n",
       "2       knn      accuracy        NaN       NaN  0.710956    858.0\n",
       "3       knn     macro avg   0.710322  0.698162  0.699995    858.0\n",
       "4       knn  weighted avg   0.710600  0.710956  0.706678    858.0\n",
       "0       svc         False   0.658031  0.795407  0.720227    479.0\n",
       "1       svc          True   0.648746  0.477573  0.550152    379.0\n",
       "2       svc      accuracy        NaN       NaN  0.655012    858.0\n",
       "3       svc     macro avg   0.653388  0.636490  0.635189    858.0\n",
       "4       svc  weighted avg   0.653929  0.655012  0.645101    858.0\n",
       "0        rf         False   0.654822  0.807933  0.723364    479.0\n",
       "1        rf          True   0.655431  0.461741  0.541796    379.0\n",
       "2        rf      accuracy        NaN       NaN  0.655012    858.0\n",
       "3        rf     macro avg   0.655127  0.634837  0.632580    858.0\n",
       "4        rf  weighted avg   0.655091  0.655012  0.643161    858.0\n",
       "0  logistic         False   0.639042  0.724426  0.679061    479.0\n",
       "1  logistic          True   0.580952  0.482850  0.527378    379.0\n",
       "2  logistic      accuracy        NaN       NaN  0.617716    858.0\n",
       "3  logistic     macro avg   0.609997  0.603638  0.603219    858.0\n",
       "4  logistic  weighted avg   0.613383  0.617716  0.612058    858.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = []\n",
    "\n",
    "for name, search in zip(names, searches):\n",
    "    print(f\"### {name}\")\n",
    "\n",
    "    # fit\n",
    "    pipeline = search.best_estimator_\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_preds.append(y_pred) \n",
    "    \n",
    "dicts = [classification_report(y_test, y_pred, output_dict=True) for y_pred in y_preds]\n",
    "df = report.combine_classification_reports(dicts, names)\n",
    "df.to_excel(proj_dir/\"data\"/\"artefacts\"/\"baseline_models.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08e2e84546486c2044445a736a214ed62f1a22506b89afaacfc141956dd76d05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
